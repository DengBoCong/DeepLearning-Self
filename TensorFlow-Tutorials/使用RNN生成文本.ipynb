{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "使用RNN生成文本.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8hWCOBMuqjt7QAkJoBjLB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IWEFAsf6RdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "80b1cffd-2be5-481d-e1cb-ce2f846ffd4c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# print('Length of text: {} characters'.format(len(text)))\n",
        "\n",
        "# print(text[:250])\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "# print('{} unique characters'.format(len(vocab)))\n",
        "\n",
        "\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# print(text)\n",
        "# print(char2idx[text[1]])\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "# print('{')\n",
        "# for char,_ in zip(char2idx, range(20)):\n",
        "#   print(' {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "# print(' ...\\n}')\n",
        "\n",
        "# print('{} ---- characters mapped to int ----> {}'.format(repr(text[:13]), text_as_int[:13]))\n",
        "\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "# for i in char_dataset.take(10):\n",
        "#   print(idx2char[i.numpy()])\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# for item in sequences.take(5):\n",
        "#   print(repr(''.join(idx2char[item.numpy()])))\n",
        "\n",
        "\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "# for input_example, target_example in dataset.take(1):\n",
        "#   print('Input data:', repr(''.join(idx2char[input_example.numpy()])))\n",
        "#   print('Target data:', repr(''.join(idx2char[target_example.numpy()])))\n",
        "\n",
        "# print(input_example)\n",
        "\n",
        "# for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "#   print('Step {:4d}'.format(i))\n",
        "#   print(' input: {} ({:s})'.format(input_idx, repr(idx2char[input_idx])))\n",
        "#   print(' expected output: {} ({:s})'.format(target_idx, repr(idx2char[target_idx])))\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# print(dataset)\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# dataset\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                batch_input_shape=[batch_size, None]),\n",
        "    keras.layers.GRU(rnn_units,\n",
        "            return_sequences=True,\n",
        "            stateful=True,\n",
        "            recurrent_initializer='glorot_uniform'),\n",
        "    keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "# model = build_model(vocab_size=len(vocab),\n",
        "#             embedding_dim=embedding_dim,\n",
        "#             rnn_units=rnn_units,\n",
        "#             batch_size=BATCH_SIZE)\n",
        "\n",
        "# for input_example_batch, target_example_batch in dataset.take(1):\n",
        "#   example_batch_predictions = model(input_example_batch)\n",
        "#   print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "# sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "# sampled_indices\n",
        "\n",
        "# print('Input: \\n', repr(''.join(idx2char[input_example_batch[0]])))\n",
        "# print()\n",
        "# print('Next Char Predictions: \\n', repr(''.join(idx2char[sampled_indices])))\n",
        "\n",
        "\n",
        "# def loss(labels, logits):\n",
        "#   return keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "# example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "# print('Prediction shape:', example_batch_predictions.shape, '# sampled_indices')\n",
        "# print('scalar_loss:     ', example_batch_loss.numpy().mean())\n",
        "\n",
        "\n",
        "# model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "# checkpoint_dir = './sample_data/training_checkpoints_t'\n",
        "# checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
        "\n",
        "# checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "#   filepath=checkpoint_prefix,\n",
        "#   save_weights_only=True\n",
        "# )\n",
        "\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# EPOCHS=10\n",
        "# history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
        "\n",
        "def generate_text(model, start_string):\n",
        "  num_generate = 1000\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "  temperature = 1\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n",
        "\n",
        "print(generate_text(model, start_string=u'ROMEO: '))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: this, as I love these vent in banish'd,\n",
            "That Katharine he hath blest from the kinsman's daughter\n",
            "Even of proceeding he is.\n",
            "\n",
            "Rubout:\n",
            "Stay, atide, adieu, a little way, at the dellow of\n",
            "master, your honour, daughter,\n",
            "Rell ruth is an apparel to your love;\n",
            "In acrives wrong troop of his thanks.\n",
            "\n",
            "WARWICK:\n",
            "Your grandship'st my vile very father, stoop as.\n",
            "You? are there? as I smotly queen, and look the gentleman of nothing out?\n",
            "\n",
            "HORTENSIO:\n",
            "Go, dread it, and I will cannot Marcius.\n",
            "\n",
            "ARIEL:\n",
            "Unturnay Ember, han, if you Margaine throught your own\n",
            "persuasion, and, uped no groans under jays,\n",
            "yhe disposted afation\n",
            "np crededits\n",
            "At holy issue overted to death branches me.\n",
            "A poxy will, sweet scorn at Barnardin a-day.\n",
            "\n",
            "FRIAR LAURENES:\n",
            "In it slain my face; and it is my sceptre,\n",
            "Love sword to's mine: I: both your was never be with sword\n",
            "One of thy 'parities and increase first say own itself,\n",
            "Accept infall'd than sprength the city.\n",
            "\n",
            "CLIFFORD:\n",
            "Mistrust down with me, and, as I ever made\n",
            "With grick in's courtern\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF0E_AXPFTAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
